{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# 🚀 DeepSeek R1 蒸馏版 Qwen 1.5B 模型部署实验\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/LLM-101/blob/main/chapter03-llm-deploy/vllm/deepseek_r1_distill_qwen_fast_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "## 📋 项目简介\n",
        "\n",
        "本项目展示如何在 Google Colab 免费环境中使用 VLLM 部署 DeepSeek R1 蒸馏版 Qwen 1.5B 模型，并通过 FastAPI 提供 RESTful API 服务。\n",
        "\n",
        "### 🎯 学习目标\n",
        "- 了解如何在 Colab 中部署大语言模型\n",
        "- 掌握 VLLM 的基本使用方法\n",
        "- 学会创建 FastAPI 服务接口\n",
        "- 理解模型推理和流式输出的实现\n",
        "\n",
        "### 💡 技术栈\n",
        "- **VLLM**: 高性能大语言模型推理引擎\n",
        "- **FastAPI**: 现代化的 Python Web 框架\n",
        "- **DeepSeek R1**: 先进的推理能力模型\n",
        "- **Google Colab**: 免费的 GPU 云计算平台"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPVYg0Z9SxCq"
      },
      "source": [
        "## 📖 关于 DeepSeek R1 蒸馏版 Qwen 1.5B 模型\n",
        "\n",
        "### 🧠 模型特点\n",
        "- **模型名称**: `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`\n",
        "- **参数规模**: 15亿参数，适合在免费 GPU 上运行\n",
        "- **推理能力**: 继承了 DeepSeek R1 的强大推理能力\n",
        "- **蒸馏技术**: 通过知识蒸馏获得更小但高效的模型\n",
        "\n",
        "### 🔍 模型优势\n",
        "1. **轻量化**: 15亿参数，内存占用小\n",
        "2. **高效推理**: 优化的推理速度\n",
        "3. **强大能力**: 保持了大模型的推理能力\n",
        "4. **免费部署**: 适合在 Colab T4 GPU 上运行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojg0UqLRnp1i"
      },
      "source": [
        "## 🎯 实验目标\n",
        "\n",
        "本实验旨在帮助大模型技术初学者：\n",
        "\n",
        "### 📚 学习内容\n",
        "1. **环境准备**: 了解如何检查和配置 Colab 环境\n",
        "2. **依赖安装**: 学习安装 VLLM、FastAPI 等关键库\n",
        "3. **模型部署**: 掌握使用 VLLM 部署大语言模型的方法\n",
        "4. **API 开发**: 创建 RESTful API 接口服务\n",
        "5. **实时交互**: 实现流式输出和实时对话功能\n",
        "\n",
        "### 💰 成本优势\n",
        "- **完全免费**: 使用 Google Colab 免费 T4 GPU (15GB 显存)\n",
        "- **零配置**: 无需本地环境配置，浏览器即可运行\n",
        "- **即开即用**: 一键启动，快速体验大模型部署\n",
        "\n",
        "### 🚀 期望收获\n",
        "通过本实验，您将掌握：\n",
        "- 大语言模型的基本部署流程\n",
        "- VLLM 推理引擎的使用方法\n",
        "- FastAPI Web 服务的开发技巧\n",
        "- 模型 API 的设计和实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LtZRZL_7jzo"
      },
      "source": [
        "## 🔧 第一步：环境信息检查\n",
        "\n",
        "在开始部署模型之前，我们需要了解当前的运行环境。这个步骤非常重要，因为：\n",
        "\n",
        "### 🎯 检查目的\n",
        "1. **硬件确认**: 确保有足够的 GPU 显存运行模型\n",
        "2. **系统兼容**: 验证操作系统和 Python 版本\n",
        "3. **资源评估**: 了解可用的 CPU、内存和存储空间\n",
        "4. **环境配置**: 检查 CUDA 版本和相关依赖\n",
        "\n",
        "### 📊 检查内容\n",
        "- **操作系统**: Linux 发行版和版本\n",
        "- **CPU 信息**: 处理器型号和核心数\n",
        "- **内存状态**: 总内存和可用内存\n",
        "- **GPU 配置**: 显卡型号和显存大小\n",
        "- **CUDA 版本**: 深度学习框架支持\n",
        "- **Python 环境**: 解释器版本\n",
        "- **磁盘空间**: 可用存储空间"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQMi5m-R7fLB",
        "outputId": "b588c9c4-8941-4521-b8e3-bfe63d11a630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "### 环境信息\n",
            "| 项目         | 信息                                                               |\n",
            "|:-------------|:-------------------------------------------------------------------|\n",
            "| 操作系统     | Linux Ubuntu 22.04.4 LTS                                           |\n",
            "| CPU 信息     | Intel(R) Xeon(R) CPU @ 2.20GHz (1 physical cores, 2 logical cores) |\n",
            "| 内存信息     | 12.67 GB (Available: 11.05 GB)                                     |\n",
            "| GPU 信息     | Tesla T4 (15360 MiB)                                               |\n",
            "| CUDA 信息    | 12.5                                                               |\n",
            "| Python 版本  | 3.11.13                                                            |\n",
            "| Conda 版本   | Conda not found                                                    |\n",
            "| 物理磁盘空间 | Total: 112.64 GB, Used: 41.16 GB, Free: 71.46 GB                   |\n"
          ]
        }
      ],
      "source": [
        "# 🔍 环境信息检查脚本\n",
        "#\n",
        "# 本脚本的作用：\n",
        "# 1. 安装 pandas 库用于数据表格展示\n",
        "# 2. 检查系统的各项配置信息\n",
        "# 3. 生成详细的环境报告表格\n",
        "#\n",
        "# 对于初学者来说，这个步骤帮助您：\n",
        "# - 了解当前运行环境的硬件配置\n",
        "# - 确认是否满足模型运行的最低要求\n",
        "# - 学习如何通过代码获取系统信息\n",
        "\n",
        "# 安装 pandas 库 - 用于创建和展示数据表格\n",
        "# pandas 是 Python 中最流行的数据处理和分析库\n",
        "!pip install pandas==2.2.2\n",
        "\n",
        "import platform # 导入 platform 模块以获取系统信息\n",
        "import os # 导入 os 模块以与操作系统交互\n",
        "import subprocess # 导入 subprocess 模块以运行外部命令\n",
        "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
        "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
        "\n",
        "# 获取 CPU 信息的函数，包括核心数量\n",
        "def get_cpu_info():\n",
        "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
        "    physical_cores = \"N/A\"\n",
        "    logical_cores = \"N/A\"\n",
        "\n",
        "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
        "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
        "        try:\n",
        "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
        "            import wmi\n",
        "            c = wmi.WMI()\n",
        "            for proc in c.Win32_Processor():\n",
        "                physical_cores = proc.NumberOfCores\n",
        "                logical_cores = proc.NumberOfLogicalProcessors\n",
        "        except:\n",
        "            pass # 如果 WMI 不可用，忽略错误\n",
        "\n",
        "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
        "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
        "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
        "        try:\n",
        "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout_brand, stderr_brand = process_brand.communicate()\n",
        "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
        "\n",
        "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout_physical, stderr_physical = process_physical.communicate()\n",
        "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
        "\n",
        "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout_logical, stderr_logical = process_logical.communicate()\n",
        "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
        "\n",
        "        except:\n",
        "            cpu_info = \"Could not retrieve CPU info\"\n",
        "            physical_cores = \"N/A\"\n",
        "            logical_cores = \"N/A\"\n",
        "\n",
        "    else:  # Linux 系统\n",
        "        try:\n",
        "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
        "            with open('/proc/cpuinfo') as f:\n",
        "                physical_cores_count = 0\n",
        "                logical_cores_count = 0\n",
        "                cpu_info_lines = []\n",
        "                for line in f:\n",
        "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
        "                        if not cpu_info: # 只获取第一个 model name\n",
        "                            cpu_info = line.split(': ')[1].strip()\n",
        "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
        "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
        "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
        "                        logical_cores_count += 1\n",
        "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
        "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
        "                if not cpu_info:\n",
        "                     cpu_info = \"Could not retrieve CPU info\"\n",
        "\n",
        "        except:\n",
        "            cpu_info = \"Could not retrieve CPU info\"\n",
        "            physical_cores = \"N/A\"\n",
        "            logical_cores = \"N/A\"\n",
        "\n",
        "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
        "\n",
        "\n",
        "# 获取内存信息的函数\n",
        "def get_memory_info():\n",
        "    mem_info = \"\" # 初始化内存信息字符串\n",
        "    if platform.system() == \"Windows\":\n",
        "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
        "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
        "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
        "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
        "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
        "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
        "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
        "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
        "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
        "    else:  # Linux 系统\n",
        "        try:\n",
        "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
        "            with open('/proc/meminfo') as f:\n",
        "                total_mem_kb = 0\n",
        "                available_mem_kb = 0\n",
        "                for line in f:\n",
        "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
        "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
        "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
        "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
        "\n",
        "                if total_mem_kb > 0:\n",
        "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
        "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
        "                    if available_mem_kb > 0:\n",
        "                        available_mem_gb = available_mem_kb / (1024**2)\n",
        "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
        "                else:\n",
        "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
        "\n",
        "        except:\n",
        "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
        "    return mem_info # 返回内存信息\n",
        "\n",
        "# 获取 GPU 信息的函数，包括显存\n",
        "def get_gpu_info():\n",
        "    try:\n",
        "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
        "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
        "        if result.returncode == 0: # 如果命令成功执行\n",
        "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
        "            gpu_info_list = []\n",
        "            for line in gpu_lines:\n",
        "                name, memory = line.split(', ')\n",
        "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
        "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
        "        else:\n",
        "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
        "            try:\n",
        "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
        "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
        "                     # 简单解析输出中的 product 名称和显存\n",
        "                    gpu_info_lines = []\n",
        "                    current_gpu = {}\n",
        "                    for line in result_lshw.stdout.splitlines():\n",
        "                        if 'product:' in line:\n",
        "                             if current_gpu:\n",
        "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
        "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
        "                        elif 'size:' in line and 'memory' in line:\n",
        "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
        "\n",
        "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
        "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
        "\n",
        "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
        "                else:\n",
        "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
        "            except FileNotFoundError:\n",
        "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
        "    except FileNotFoundError:\n",
        "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
        "\n",
        "\n",
        "# 获取 CUDA 版本的函数\n",
        "def get_cuda_version():\n",
        "    try:\n",
        "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
        "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0: # 如果命令成功执行\n",
        "            for line in result.stdout.splitlines():\n",
        "                if 'release' in line: # 查找包含 'release' 的行\n",
        "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
        "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
        "    except FileNotFoundError:\n",
        "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
        "\n",
        "# 获取 Python 版本的函数\n",
        "def get_python_version():\n",
        "    return platform.python_version() # 获取 Python 版本\n",
        "\n",
        "# 获取 Conda 版本的函数\n",
        "def get_conda_version():\n",
        "    try:\n",
        "        # 尝试使用 conda --version 获取 Conda 版本\n",
        "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0: # 如果命令成功执行\n",
        "            return result.stdout.strip() # 返回 Conda 版本\n",
        "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
        "    except FileNotFoundError:\n",
        "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
        "\n",
        "# 获取物理磁盘空间信息的函数\n",
        "def get_disk_space():\n",
        "    try:\n",
        "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
        "        total_gb = total / (1024**3) # 转换为 GB\n",
        "        used_gb = used / (1024**3) # 转换为 GB\n",
        "        free_gb = free / (1024**3) # 转换为 GB\n",
        "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
        "\n",
        "# 获取环境信息\n",
        "os_name = platform.system() # 获取操作系统名称\n",
        "os_version = platform.release() # 获取操作系统版本\n",
        "if os_name == \"Linux\":\n",
        "    try:\n",
        "        # 在 Linux 上尝试获取发行版和版本\n",
        "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
        "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
        "            for line in lsb_info.stdout.splitlines():\n",
        "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
        "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
        "                    break # 找到后退出循环\n",
        "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
        "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
        "                     # 尝试获取 codename\n",
        "                     try:\n",
        "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
        "                         if codename_info.returncode == 0:\n",
        "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
        "                     except:\n",
        "                         pass # 如果获取 codename 失败则忽略\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        pass # lsb_release 可能未安装，忽略错误\n",
        "\n",
        "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
        "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
        "memory_info = get_memory_info() # 调用函数获取内存信息\n",
        "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
        "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
        "python_version = get_python_version() # 调用函数获取 Python 版本\n",
        "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
        "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
        "\n",
        "\n",
        "# 创建用于存储数据的字典\n",
        "env_data = {\n",
        "    \"项目\": [ # 项目名称列表\n",
        "        \"操作系统\",\n",
        "        \"CPU 信息\",\n",
        "        \"内存信息\",\n",
        "        \"GPU 信息\",\n",
        "        \"CUDA 信息\",\n",
        "        \"Python 版本\",\n",
        "        \"Conda 版本\",\n",
        "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
        "    ],\n",
        "    \"信息\": [ # 对应的信息列表\n",
        "        full_os_info,\n",
        "        cpu_info,\n",
        "        memory_info,\n",
        "        gpu_info,\n",
        "        cuda_version,\n",
        "        python_version,\n",
        "        conda_version,\n",
        "        disk_info # 添加物理磁盘空间信息\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 创建一个 pandas DataFrame\n",
        "df = pd.DataFrame(env_data)\n",
        "\n",
        "# 打印表格\n",
        "print(\"### 环境信息\") # 打印标题\n",
        "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj_P8PUQjFFT"
      },
      "source": [
        "## 📦 第二步：安装依赖包\n",
        "\n",
        "现在我们需要安装运行模型所需的关键 Python 包：\n",
        "\n",
        "### 🔧 核心依赖说明\n",
        "\n",
        "#### 1. **FastAPI (0.116.0)**\n",
        "- **作用**: 现代化的 Python Web 框架\n",
        "- **用途**: 创建 RESTful API 接口服务\n",
        "- **特点**: 自动生成 API 文档，支持异步处理\n",
        "\n",
        "#### 2. **nest-asyncio (1.6.0)**\n",
        "- **作用**: 允许在已有事件循环中运行异步代码\n",
        "- **用途**: 解决 Jupyter 环境中的异步兼容问题\n",
        "- **重要性**: 确保 FastAPI 在 Colab 中正常运行\n",
        "\n",
        "#### 3. **pyngrok (7.2.12)**\n",
        "- **作用**: Python 版本的 ngrok 客户端\n",
        "- **用途**: 创建公网隧道，让外部访问本地服务\n",
        "- **场景**: 将 Colab 中的 API 服务暴露给外部\n",
        "\n",
        "#### 4. **uvicorn (0.35.0)**\n",
        "- **作用**: 高性能的 ASGI 服务器\n",
        "- **用途**: 运行 FastAPI 应用程序\n",
        "- **特点**: 支持异步处理，性能优异\n",
        "\n",
        "#### 5. **vllm (0.9.2)**\n",
        "- **作用**: 高性能大语言模型推理引擎\n",
        "- **用途**: 加载和运行 DeepSeek 模型\n",
        "- **优势**: 内存高效，推理速度快\n",
        "\n",
        "### ⚡ 安装过程\n",
        "下面的命令会安装所有必需的依赖包，请耐心等待安装完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ebACUjhXSwzJ",
        "outputId": "90c49ff3-3505-4ee1-ebea-e00c33273713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi==0.116.0 in /usr/local/lib/python3.11/dist-packages (0.116.0)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok==7.2.12 in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: uvicorn==0.35.0 in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: vllm==0.9.2 in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.116.0) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.116.0) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.116.0) (4.14.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok==7.2.12) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.35.0) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.35.0) (0.16.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.0.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (4.53.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm==0.9.2) (0.33.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.21.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (5.29.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (3.11.15)\n",
            "Requirement already satisfied: openai<=1.90.0,>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.90.0)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.22.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (11.2.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.10.11)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.7.30)\n",
            "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.19 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.1.19)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (3.18.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.2.1.1.post6)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (27.0.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.19.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.6.2->vllm==0.9.2) (1.7.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (4.12.0.88)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.10.2 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.10.2)\n",
            "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (3.1.1)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.1.0)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.15.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.11.1.4)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (1.4.1)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.61.2)\n",
            "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2) (2.47.1)\n",
            "Requirement already satisfied: torch==2.7.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (2.7.0)\n",
            "Requirement already satisfied: torchaudio==2.7.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (2.7.0)\n",
            "Requirement already satisfied: torchvision==0.22.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.22.0)\n",
            "Requirement already satisfied: xformers==0.0.30 in /usr/local/lib/python3.11/dist-packages (from vllm==0.9.2) (0.0.30)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm==0.9.2) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm==0.9.2) (0.3.7)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm==0.9.2) (0.44.0)\n",
            "Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (3.1.6)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (5.6.3)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (4.24.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (20250706)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm==0.9.2) (0.1.26)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm==0.9.2) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->vllm==0.9.2) (75.2.0)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.0.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2) (2.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm==0.9.2) (24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm==0.9.2) (1.1.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.116.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.116.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.116.0) (0.4.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2) (1.1.1)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.9.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.9.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.9.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.9.2) (2025.7.9)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm==0.9.2) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.9.2) (1.20.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.9.2) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.16.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.14.8)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.9.2) (1.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm==0.9.2) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2) (0.26.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->vllm==0.9.2) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2) (0.8.3)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.5.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (2.32.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 📦 批量安装依赖包\n",
        "# \n",
        "# 这里使用 pip install 命令一次性安装所有必需的包\n",
        "# 使用 \\ 符号可以将长命令分成多行，提高可读性\n",
        "# \n",
        "# 安装过程可能需要几分钟时间，请耐心等待\n",
        "# 如果出现版本冲突，系统会自动处理依赖关系\n",
        "\n",
        "!pip install \\\n",
        "    fastapi==0.116.0 \\\n",
        "    nest-asyncio==1.6.0 \\\n",
        "    pyngrok==7.2.12 \\\n",
        "    uvicorn==0.35.0 \\\n",
        "    vllm==0.9.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFI6d95RjNzd"
      },
      "source": [
        "## 🚀 第三步：启动 VLLM 模型服务\n",
        "\n",
        "现在我们将使用 VLLM 在后台启动 DeepSeek R1 蒸馏版模型服务。\n",
        "\n",
        "### 🎯 VLLM 服务启动说明\n",
        "\n",
        "#### 🔍 模型选择\n",
        "- **模型来源**: [Hugging Face DeepSeek AI](https://huggingface.co/deepseek-ai/DeepSeek-R1#3-model-downloads)\n",
        "- **当前模型**: `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`\n",
        "- **参数规模**: 15亿参数，适合 T4 GPU 运行\n",
        "- **替换选项**: 可以替换为其他 DeepSeek R1 系列模型\n",
        "\n",
        "#### ⚙️ VLLM 参数解释\n",
        "- `serve`: VLLM 的服务模式命令\n",
        "- `--trust-remote-code`: 允许执行远程代码（模型配置）\n",
        "- `--dtype half`: 使用半精度浮点数，节省显存\n",
        "- `--max-model-len 16384`: 最大序列长度为 16K tokens\n",
        "- `--tensor-parallel-size 1`: 使用单卡推理\n",
        "\n",
        "#### 🔄 后台运行\n",
        "模型将在后台启动，不会阻塞当前进程，这样我们可以继续执行其他代码。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "E4FjRHNbcFYl"
      },
      "outputs": [],
      "source": [
        "# 🚀 启动 VLLM 模型服务\n",
        "# \n",
        "# 这个单元格的作用：\n",
        "# 1. 导入必要的 Python 模块\n",
        "# 2. 配置模型参数\n",
        "# 3. 使用 subprocess 在后台启动 VLLM 服务\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# 📝 可选：配置 Hugging Face 镜像源\n",
        "# 如果在中国大陆访问 Hugging Face 较慢，可以启用下面这行\n",
        "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
        "\n",
        "# 🎯 模型配置\n",
        "# 指定要使用的模型名称\n",
        "# 这里使用的是 DeepSeek R1 的蒸馏版本，参数量为 15亿\n",
        "model = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
        "\n",
        "# 🔧 启动 VLLM 服务器\n",
        "# 使用 subprocess.Popen 在后台启动服务，这样不会阻塞当前进程\n",
        "print(f\"🚀 正在启动 VLLM 服务，模型: {model}\")\n",
        "print(\"⏳ 首次运行需要下载模型，请耐心等待...\")\n",
        "\n",
        "vllm_process = subprocess.Popen([\n",
        "    'vllm',                      # VLLM 命令\n",
        "    'serve',                     # 服务模式\n",
        "    model,                       # 模型名称\n",
        "    '--trust-remote-code',       # 信任远程代码\n",
        "    '--dtype', 'half',           # 使用半精度浮点数\n",
        "    '--max-model-len', '16384',  # 最大序列长度\n",
        "    '--tensor-parallel-size', '1' # 单卡推理\n",
        "], stdout=subprocess.PIPE, stderr=subprocess.PIPE, start_new_session=True)\n",
        "\n",
        "print(\"✅ VLLM 服务启动命令已执行，正在后台加载模型...\")\n",
        "print(\"📡 服务将在 http://localhost:8000 上运行\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCR-O8i9lEbb"
      },
      "source": [
        "## 🔍 第四步：监控 VLLM 服务状态\n",
        "\n",
        "由于 VLLM 在后台运行，我们需要监控其启动状态。\n",
        "\n",
        "### 🎯 监控的重要性\n",
        "\n",
        "#### 🔄 为什么需要监控？\n",
        "- **异步启动**: VLLM 在后台启动，需要时间加载模型\n",
        "- **状态确认**: 确保服务正常运行后再进行后续操作\n",
        "- **错误诊断**: 及时发现和处理启动过程中的问题\n",
        "- **资源管理**: 监控进程状态，避免资源泄漏\n",
        "\n",
        "#### ⏱️ 启动时间说明\n",
        "- **首次运行**: 需要下载模型文件，可能需要 5-10 分钟\n",
        "- **后续运行**: 模型已缓存，启动时间约 1-2 分钟\n",
        "- **检查频率**: 每 5 秒检查一次服务状态\n",
        "\n",
        "#### 🚦 状态检查机制\n",
        "- **健康检查**: 通过 HTTP 请求检查服务是否可用\n",
        "- **进程监控**: 监控 VLLM 进程的运行状态\n",
        "- **日志输出**: 显示启动过程中的关键信息"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bx5v9mXkvqPo"
      },
      "outputs": [],
      "source": [
        "# 🔍 VLLM 服务监控函数\n",
        "# \n",
        "# 这个单元格定义了两个重要的监控函数：\n",
        "# 1. check_vllm_status: 检查 VLLM 服务是否可用\n",
        "# 2. monitor_vllm_process: 持续监控 VLLM 进程状态\n",
        "\n",
        "import requests\n",
        "import time\n",
        "from typing import Tuple\n",
        "import sys\n",
        "\n",
        "def check_vllm_status(url: str = \"http://localhost:8000/health\") -> bool:\n",
        "    \"\"\"\n",
        "    🏥 检查 VLLM 服务器健康状态\n",
        "    \n",
        "    参数:\n",
        "        url: 健康检查的 URL 地址\n",
        "    \n",
        "    返回:\n",
        "        bool: True 表示服务正常，False 表示服务不可用\n",
        "    \n",
        "    工作原理:\n",
        "        向 VLLM 的健康检查端点发送 GET 请求\n",
        "        如果返回 200 状态码，说明服务正常运行\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        return response.status_code == 200\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return False\n",
        "    except requests.exceptions.Timeout:\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def monitor_vllm_process(vllm_process: subprocess.Popen, check_interval: int = 5) -> Tuple[bool, str, str]:\n",
        "    \"\"\"\n",
        "    📊 监控 VLLM 进程的启动状态\n",
        "    \n",
        "    参数:\n",
        "        vllm_process: VLLM 进程对象\n",
        "        check_interval: 检查间隔时间（秒）\n",
        "    \n",
        "    返回:\n",
        "        Tuple[bool, str, str]: (是否成功, 标准输出, 标准错误)\n",
        "    \n",
        "    工作流程:\n",
        "        1. 循环检查进程是否还在运行\n",
        "        2. 定期检查服务健康状态\n",
        "        3. 输出进程的日志信息\n",
        "        4. 返回最终状态\n",
        "    \"\"\"\n",
        "    print(\"🔍 开始 VLLM 服务器监控...\")\n",
        "    print(\"⏳ 正在等待服务启动，请耐心等待...\")\n",
        "\n",
        "    while vllm_process.poll() is None:  # 当进程仍在运行时\n",
        "        # 检查服务是否已经可用\n",
        "        if check_vllm_status():\n",
        "            print(\"✅ VLLM 服务器已启动并运行！\")\n",
        "            print(\"🎉 服务地址: http://localhost:8000\")\n",
        "            return True, \"\", \"\"\n",
        "\n",
        "        print(\"⏳ 等待 VLLM 服务器启动...\")\n",
        "        time.sleep(check_interval)\n",
        "\n",
        "        # 检查并输出进程日志\n",
        "        if vllm_process.stdout and vllm_process.stdout.readable():\n",
        "            try:\n",
        "                stdout = vllm_process.stdout.read1(1024).decode('utf-8')\n",
        "                if stdout.strip():\n",
        "                    print(\"📝 标准输出:\", stdout.strip())\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if vllm_process.stderr and vllm_process.stderr.readable():\n",
        "            try:\n",
        "                stderr = vllm_process.stderr.read1(1024).decode('utf-8')\n",
        "                if stderr.strip():\n",
        "                    print(\"⚠️ 标准错误:\", stderr.strip())\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # 如果到达这里，进程已结束（可能是错误）\n",
        "    print(\"❌ VLLM 进程已结束\")\n",
        "    try:\n",
        "        stdout, stderr = vllm_process.communicate(timeout=5)\n",
        "        return False, stdout.decode('utf-8'), stderr.decode('utf-8')\n",
        "    except Exception:\n",
        "        return False, \"\", \"进程通信超时\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEbWUS2nvRJo",
        "outputId": "b36e0d60-ce7b-48c7-9e91-8e22c4fbab41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始 VLLM 服务器监控...\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:38:18 [__init__.py:244] Automatically detected platform cuda.\n",
            "\n",
            "标准错误: 2025-07-13 04:38:12.434183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752381492.454585   13234 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752381492.460791   13234 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-13 04:38:12.481583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:38:22 [api_server.py:1395] vLLM API server version 0.9.2\n",
            "INFO 07-13 04:38:22 [cli_args.py:325] non-default args: {'model': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'trust_remote_code': True, 'dtype': 'half', 'max_model_len': 16384}\n",
            "\n",
            "标准错误: 2025-07-13 04:38:41.664026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:38:37 [config.py:841] This model supports multiple tasks: {'classify', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.\n",
            "WARNING 07-13 04:38:37 [config.py:3371] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 07-13 04:38:37 [config.py:1472] Using max model len 16384\n",
            "WARNING 07-13 04:38:37 [arg_utils.py:1735] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
            "INFO 07-13 04:38:37 [api_server.py:268] Started engine process with PID 13429\n",
            "\n",
            "标准错误: WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752381521.685109   13429 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752381521.691083   13429 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:38:47 [__init__.py:244] Automatically detected platform cuda.\n",
            "INFO 07-13 04:38:49 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=True, \n",
            "INFO 07-13 04:38:51 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 07-13 04:38:51 [cuda.py:360] Using XFormers backend.\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:38:52 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 07-13 04:38:52 [model_runner.py:1171] Starting to load model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B...\n",
            "INFO 07-13 04:38:53 [weight_utils.py:292] Using model weights format ['*.safetensors']\n",
            "INFO 07-13 04:40:25 [weight_utils.py:308] Time spent downloading weights for deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B: 92.364174 seconds\n",
            "INFO 07-13 04:40:26 [weight_utils.py:345] No model.safetensors.index.json found in remote.\n",
            "\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:06<00:00,  6.80s/it]\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:40:33 [default_loader.py:272] Loading weights took 6.89 seconds\n",
            "INFO 07-13 04:40:33 [model_runner.py:1203] Model loading took 3.3461 GiB and 100.233800 seconds\n",
            "INFO 07-13 04:40:37 [worker.py:294] Memory profiling takes 3.07 seconds\n",
            "INFO 07-13 04:40:37 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
            "INFO 07-13 04:40:37 [worker.py:294] model weights take 3.35GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.43GiB; the rest of the memory reserved for KV Cache is 8.44GiB.\n",
            "INFO 07-13 04:40:37 [executor_base.py:113] # cuda blocks: 19758, # CPU blocks: 9362\n",
            "INFO 07-13 04:40:37 [executor_base.py:118] Maximum concurrency for 16384 tokens per request: 19.29x\n",
            "\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:06<00:00,  6.80s/it]\n",
            "\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:40:42 [model_runner.py:1513] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
            "\n",
            "Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:41:33 [model_runner.py:1671] Graph capturing finished in 51 secs, took 0.19 GiB\n",
            "\n",
            "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:50<00:00,  1.45s/it]\n",
            "\n",
            "等待 VLLM 服务器启动...\n",
            "标准输出: INFO 07-13 04:41:33 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 59.61 seconds\n",
            "WARNING 07-13 04:41:34 [config.py:1392] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.\n",
            "INFO 07-13 04:41:34 [serving_chat.py:125] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
            "INFO 07-13 04:41:35 [serving_completion.py:72] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
            "INFO 07-13 04:41:35 [api_server.py:1457] Starting vLLM API server 0 on http://0.0.0.0:8000\n",
            "INFO 07-13 04:41:35 [launcher.py:29] Available routes are:\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /openapi.json, Methods: GET, HEAD\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /docs, Methods: GET, HEAD\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /docs/oauth2-redirect, Methods: GET, HEAD\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /redoc, Methods: GET, HEAD\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /health, Methods: GET\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /load, Methods: GET\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /ping, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /ping, Methods: GET\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /tokenize, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /detokenize, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/models, Methods: GET\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /version, Methods: GET\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/chat/completions, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/completions, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/embeddings, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /pooling, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /classify, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /score, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/score, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/audio/transcriptions, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/audio/translations, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /rerank, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v1/rerank, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /v2/rerank, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /invocations, Methods: POST\n",
            "INFO 07-13 04:41:35 [launcher.py:37] Route: /metrics, Methods: GET\n",
            "\n",
            "标准错误: INFO:     Started server process [13234]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "\n",
            "✓ VLLM 服务器已启动并运行！\n"
          ]
        }
      ],
      "source": [
        "# 🚀 执行 VLLM 服务监控\n",
        "# \n",
        "# 这个单元格的作用：\n",
        "# 1. 调用监控函数，等待 VLLM 服务启动\n",
        "# 2. 处理启动成功和失败的情况\n",
        "# 3. 支持用户中断操作\n",
        "\n",
        "print(\"🎯 开始监控 VLLM 服务启动状态...\")\n",
        "print(\"💡 提示：首次运行可能需要 5-10 分钟下载模型\")\n",
        "print(\"⌨️  按 Ctrl+C 可以中断监控（但不会停止 VLLM 服务）\")\n",
        "\n",
        "try:\n",
        "    # 调用监控函数，等待服务启动\n",
        "    success, stdout, stderr = monitor_vllm_process(vllm_process)\n",
        "\n",
        "    if not success:\n",
        "        print(\"\\n❌ VLLM 服务器启动失败！\")\n",
        "        print(\"\\n📋 完整标准输出:\")\n",
        "        print(stdout)\n",
        "        print(\"\\n🚨 完整标准错误:\")\n",
        "        print(stderr)\n",
        "        print(\"\\n🔧 可能的解决方案:\")\n",
        "        print(\"1. 检查 GPU 内存是否足够\")\n",
        "        print(\"2. 确认模型名称是否正确\")\n",
        "        print(\"3. 重新运行安装依赖包的单元格\")\n",
        "        sys.exit(1)\n",
        "    else:\n",
        "        print(\"\\n🎉 VLLM 服务启动成功！\")\n",
        "        print(\"📡 API 服务地址: http://localhost:8000\")\n",
        "        print(\"📚 API 文档地址: http://localhost:8000/docs\")\n",
        "        print(\"✅ 现在可以继续运行后续单元格\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n⚠️ 用户中断监控\")\n",
        "    print(\"💡 注意：VLLM 服务仍在后台运行\")\n",
        "    print(\"🔄 如果需要停止 VLLM 服务，请重启 Colab 运行时\")\n",
        "    \n",
        "    # 可选：强制停止 VLLM 进程\n",
        "    # 取消下面的注释可以在中断时停止服务\n",
        "    # print(\"🛑 正在停止 VLLM 服务...\")\n",
        "    # vllm_process.terminate()\n",
        "    # try:\n",
        "    #     vllm_process.wait(timeout=5)\n",
        "    #     print(\"✅ VLLM 服务已停止\")\n",
        "    # except subprocess.TimeoutExpired:\n",
        "    #     vllm_process.kill()\n",
        "    #     print(\"⚡ 强制终止 VLLM 服务\")\n",
        "\n",
        "    # 输出最终日志信息\n",
        "    try:\n",
        "        stdout, stderr = vllm_process.communicate(timeout=2)\n",
        "        if stdout: \n",
        "            print(\"\\n📝 最终标准输出:\")\n",
        "            print(stdout.decode('utf-8'))\n",
        "        if stderr: \n",
        "            print(\"\\n⚠️ 最终标准错误:\")\n",
        "            print(stderr.decode('utf-8'))\n",
        "    except:\n",
        "        print(\"📝 无法获取最终日志\")\n",
        "    \n",
        "    sys.exit(0)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "QHgjENDr7WHp",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🧪 第五步：测试模型推理功能\n",
        "\n",
        "VLLM 服务启动成功后，我们需要测试模型是否能正常进行推理。\n",
        "\n",
        "### 🎯 测试目标\n",
        "\n",
        "#### 📝 功能验证\n",
        "1. **基础推理**: 测试模型能否正确回答问题\n",
        "2. **API 接口**: 验证 OpenAI 兼容的 API 格式\n",
        "3. **响应质量**: 检查模型输出的准确性和流畅度\n",
        "4. **性能测试**: 评估推理速度和资源消耗\n",
        "\n",
        "#### 🔧 测试内容\n",
        "- **单次推理**: 发送一个问题，获取完整回答\n",
        "- **流式推理**: 实时获取模型的生成过程\n",
        "- **多轮对话**: 测试上下文理解能力\n",
        "- **不同语言**: 测试中英文处理能力\n",
        "\n",
        "### 📊 API 格式说明\n",
        "VLLM 提供了 OpenAI 兼容的 API 接口：\n",
        "- **端点**: `/v1/chat/completions`\n",
        "- **格式**: 标准的 ChatGPT API 格式\n",
        "- **支持**: 流式和非流式两种模式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb6UVM067WHp",
        "outputId": "fd83e5e8-4267-4f7f-af0b-4211b5aeceb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-fb76a1f996944aa092e1a5ca6ee0c8c8\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1752381887,\n",
            "  \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"reasoning_content\": null,\n",
            "        \"content\": \"\\u55ef\\uff0c\\u7528\\u6237\\u95ee\\u7684\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u662f\\u4ec0\\u4e48\\u3002\\u9996\\u5148\\uff0c\\u6211\\u5f97\\u56de\\u5fc6\\u4e00\\u4e0b\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u3002\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u5e94\\u8be5\\u662f\\u5df4\\u9ece\\u3002\\u5bf9\\uff0c\\u6211\\u8bb0\\u5f97\\u5df4\\u9ece\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\uff0c\\u4e5f\\u662f\\u5386\\u53f2\\u4e0a\\u7684\\u91cd\\u8981\\u9996\\u90fd\\u4e4b\\u4e00\\u3002\\u5b83\\u4e0d\\u4ec5\\u662f\\u4e00\\u4e2a\\u57ce\\u5e02\\uff0c\\u8fd8\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\uff0c\\u6240\\u4ee5\\u7528\\u6237\\u5e94\\u8be5\\u77e5\\u9053\\u8fd9\\u4e00\\u70b9\\u3002\\n\\n\\u63a5\\u4e0b\\u6765\\uff0c\\u6211\\u5e94\\u8be5\\u89e3\\u91ca\\u4e00\\u4e0b\\u4e3a\\u4ec0\\u4e48\\u5df4\\u9ece\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u3002\\u5b83\\u4e0d\\u4ec5\\u662f\\u4e00\\u4e2a\\u7ecf\\u6d4e\\u4e2d\\u5fc3\\uff0c\\u800c\\u4e14\\u5728\\u6587\\u5316\\u3001\\u827a\\u672f\\u548c\\u653f\\u6cbb\\u65b9\\u9762\\u90fd\\u6709\\u5f88\\u5927\\u7684\\u5f71\\u54cd\\u529b\\u3002\\u6bd4\\u5982\\uff0c\\u5df4\\u9ece\\u5723\\u6bcd\\u9662\\u3001\\u57c3\\u83f2\\u5c14\\u94c1\\u5854\\uff0c\\u8fd9\\u4e9b\\u90fd\\u662f\\u6cd5\\u56fd\\u8457\\u540d\\u7684\\u5efa\\u7b51\\u548c\\u6587\\u5316\\u9057\\u4ea7\\u3002\\u6b64\\u5916\\uff0c\\u5df4\\u9ece\\u8fd8\\u662f\\u6cd5\\u56fd\\u7684\\u653f\\u6cbb\\u4e2d\\u5fc3\\uff0c\\u6cd5\\u56fd\\u653f\\u5e9c\\u7684\\u5f88\\u591a\\u91cd\\u8981\\u653f\\u7b56\\u548c\\u51b3\\u7b56\\u90fd\\u96c6\\u4e2d\\u5728\\u5df4\\u9ece\\u3002\\n\\n\\u53ef\\u80fd\\u7528\\u6237\\u8fd8\\u5bf9\\u5df4\\u9ece\\u7684\\u5730\\u7406\\u4f4d\\u7f6e\\u548c\\u5386\\u53f2\\u611f\\u5174\\u8da3\\uff0c\\u6240\\u4ee5\\u53ef\\u4ee5\\u8865\\u5145\\u4e00\\u4e0b\\u3002\\u5df4\\u9ece\\u4f4d\\u4e8e\\u6b27\\u6d32\\u4e2d\\u90e8\\uff0c\\u9760\\u8fd1\\u5927\\u897f\\u6d0b\\uff0c\\u5730\\u7406\\u4f4d\\u7f6e\\u4f18\\u8d8a\\uff0c\\u4ea4\\u901a\\u4fbf\\u5229\\u3002\\u5386\\u53f2\\u4e0a\\uff0c\\u5df4\\u9ece\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\uff0c\\u89c1\\u8bc1\\u4e86\\u6cd5\\u56fd\\u7684\\u8f89\\u714c\\uff0c\\u540e\\u6765\\u7ecf\\u5386\\u4e86\\u5927\\u9769\\u547d\\u548c\\u5927\\u5c60\\u6740\\uff0c\\u4f46\\u540e\\u6765\\u53c8\\u6062\\u590d\\u4e86\\uff0c\\u6210\\u4e3a\\u7ecf\\u6d4e\\u4e2d\\u5fc3\\u3002\\n\\n\\u53e6\\u5916\\uff0c\\u5df4\\u9ece\\u4f5c\\u4e3a\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\uff0c\\u4e0d\\u4ec5\\u5728\\u653f\\u6cbb\\u3001\\u7ecf\\u6d4e\\u3001\\u6587\\u5316\\u65b9\\u9762\\u8d77\\u7740\\u5173\\u952e\\u4f5c\\u7528\\uff0c\\u8fd8\\u5728\\u56fd\\u9645\\u821e\\u53f0\\u4e0a\\u6709\\u7740\\u91cd\\u8981\\u5730\\u4f4d\\u3002\\u6240\\u4ee5\\uff0c\\u7528\\u6237\\u53ef\\u80fd\\u5bf9\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u548c\\u5df4\\u9ece\\u7684\\u5386\\u53f2\\u80cc\\u666f\\u611f\\u5174\\u8da3\\u3002\\n\\n\\u603b\\u7ed3\\u4e00\\u4e0b\\uff0c\\u56de\\u7b54\\u7684\\u65f6\\u5019\\u8981\\u660e\\u786e\\u6307\\u51fa\\u5df4\\u9ece\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\uff0c\\u5e76\\u7b80\\u8981\\u8bf4\\u660e\\u5176\\u5386\\u53f2\\u3001\\u6587\\u5316\\u3001\\u7ecf\\u6d4e\\u548c\\u653f\\u6cbb\\u5730\\u4f4d\\uff0c\\u4ee5\\u53ca\\u5730\\u7406\\u4f4d\\u7f6e\\u3002\\u8fd9\\u6837\\u7528\\u6237\\u5c31\\u80fd\\u5168\\u9762\\u4e86\\u89e3\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u95ee\\u9898\\u3002\\n</think>\\n\\n\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\u662f\\u5df4\\u9ece\\u3002\\u5df4\\u9ece\\u662f\\u6cd5\\u56fd\\u5386\\u53f2\\u4e0a\\u7684\\u91cd\\u8981\\u9996\\u90fd\\uff0c\\u4e5f\\u662f\\u6cd5\\u56fd\\u7684\\u9996\\u90fd\\uff0c\\u4e5f\\u662f\\u6cd5\\u56fd\\u7684\\u6587\\u5316\\u3001\\u827a\\u672f\\u548c\\u653f\\u6cbb\\u7684\\u4e2d\\u5fc3\\u3002\\u5b83\\u4e0d\\u4ec5\\u662f\\u4e00\\u4e2a\\u7ecf\\u6d4e\\u4e2d\\u5fc3\\uff0c\\u8fd8\\u56e0\\u4e3a\\u5176\\u4e30\\u5bcc\\u7684\\u6587\\u5316\\u9057\\u4ea7\\u548c\\u6df1\\u539a\\u7684\\u5386\\u53f2\\u5e95\\u8574\\u800c\\u95fb\\u540d\\u4e8e\\u4e16\\u3002\\u5df4\\u9ece\\u5728\\u6b27\\u6d32\\u4e2d\\u90e8\\uff0c\\u9760\\u8fd1\\u5927\\u897f\\u6d0b\\uff0c\\u5730\\u7406\\u4f4d\\u7f6e\\u4f18\\u8d8a\\uff0c\\u4ea4\\u901a\\u4fbf\\u5229\\uff0c\\u662f\\u6cd5\\u56fd\\u7684\\u653f\\u6cbb\\u4e2d\\u5fc3\\uff0c\\u89c1\\u8bc1\\u4e86\\u6cd5\\u56fd\\u7684\\u8f89\\u714c\\u3002\",\n",
            "        \"tool_calls\": []\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"stop_reason\": null\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 11,\n",
            "    \"total_tokens\": 361,\n",
            "    \"completion_tokens\": 350,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 🧪 模型推理测试函数\n",
        "# \n",
        "# 这个单元格定义了两个核心函数：\n",
        "# 1. ask_model: 发送问题并获取完整回答\n",
        "# 2. stream_llm_response: 实现流式响应功能\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from fastapi.responses import StreamingResponse\n",
        "\n",
        "# 📝 定义请求数据模型\n",
        "class QuestionRequest(BaseModel):\n",
        "    \"\"\"\n",
        "    API 请求的数据模型\n",
        "    \n",
        "    属性:\n",
        "        question (str): 用户提出的问题\n",
        "    \n",
        "    说明:\n",
        "        使用 Pydantic 模型确保数据类型安全\n",
        "        后续 FastAPI 会自动验证请求数据\n",
        "    \"\"\"\n",
        "    question: str\n",
        "\n",
        "def ask_model(question: str):\n",
        "    \"\"\"\n",
        "    🤖 向 VLLM 模型发送问题并获取完整回答\n",
        "    \n",
        "    参数:\n",
        "        question (str): 用户提出的问题\n",
        "    \n",
        "    返回:\n",
        "        dict: 包含模型回答的 JSON 响应\n",
        "    \n",
        "    工作流程:\n",
        "        1. 构造符合 OpenAI API 格式的请求\n",
        "        2. 发送 POST 请求到 VLLM 服务\n",
        "        3. 处理响应并返回结果\n",
        "    \"\"\"\n",
        "    # VLLM 的 OpenAI 兼容 API 端点\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "    \n",
        "    # 设置请求头\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    \n",
        "    # 构造请求数据（OpenAI 格式）\n",
        "    data = {\n",
        "        \"model\": model,  # 使用全局模型变量\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 2048,  # 最大生成长度\n",
        "        \"temperature\": 0.7,  # 生成的随机性\n",
        "        \"top_p\": 0.9         # 核采样参数\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # 发送请求\n",
        "        response = requests.post(url, headers=headers, json=data, timeout=60)\n",
        "        response.raise_for_status()  # 检查 HTTP 错误\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ 请求失败: {e}\")\n",
        "        return None\n",
        "\n",
        "def stream_llm_response(question: str):\n",
        "    \"\"\"\n",
        "    🌊 流式响应生成器 - 实时获取模型输出\n",
        "    \n",
        "    参数:\n",
        "        question (str): 用户提出的问题\n",
        "    \n",
        "    生成:\n",
        "        str: 逐行返回模型的生成内容\n",
        "    \n",
        "    特点:\n",
        "        - 实时显示生成过程\n",
        "        - 降低等待时间\n",
        "        - 提供更好的用户体验\n",
        "    \"\"\"\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    \n",
        "    # 启用流式传输\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
        "        \"stream\": True,      # 🔥 关键：启用流式传输\n",
        "        \"max_tokens\": 2048,\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with requests.post(url, headers=headers, json=data, stream=True, timeout=60) as response:\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            for line in response.iter_lines():\n",
        "                if line:\n",
        "                    # OpenAI 风格的流式响应以 \"data: \" 为前缀\n",
        "                    decoded_line = line.decode(\"utf-8\")\n",
        "                    if decoded_line.startswith(\"data: \"):\n",
        "                        decoded_line = decoded_line[6:]  # 移除 \"data: \" 前缀\n",
        "                    yield decoded_line + \"\\n\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        yield f\"❌ 流式请求失败: {e}\\n\"\n",
        "\n",
        "# 🧪 测试基础推理功能\n",
        "print(\"🧪 测试模型推理功能...\")\n",
        "print(\"📝 发送测试问题: 法国的首都是什么？\")\n",
        "\n",
        "try:\n",
        "    result = ask_model(\"法国的首都是什么？\")\n",
        "    if result:\n",
        "        print(\"\\n✅ 模型推理成功！\")\n",
        "        print(\"📋 完整响应:\")\n",
        "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "        \n",
        "        # 提取并显示模型回答\n",
        "        if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
        "            answer = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "            print(f\"\\n🤖 模型回答: {answer}\")\n",
        "    else:\n",
        "        print(\"❌ 模型推理失败\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 测试过程中出现错误: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✅ 推理函数定义完成，可以继续下一步！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZkEvUzTljvK"
      },
      "source": [
        "### Running Test and defining function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt2lqQ_vfrdn",
        "outputId": "5fedc7e0-ba0c-4a17-d559-4d63a834ed4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-a9e44d3c90f34d1999541641b62eb72e\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1752381898,\n",
            "  \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"reasoning_content\": null,\n",
            "        \"content\": \"Okay, so I need to figure out the capital of France. Hmm, where do I start? I remember that France is a big country in Europe, and it's known for having beautiful landscapes and a rich history. I think the capital is a significant city, maybe in the south? I've heard terms like \\\"Paris\\\" before, but I'm not sure if that's the actual capital.\\n\\nWait, I think Paris is the capital of France, but I'm not entirely certain. Let me think about what I know. France is part of the European Union, right? And I believe the EU capitals are usually in the EU, like the EU capital of another country. But France itself is a country, so its capital should be a city within France.\\n\\nI recall that Paris was the capital before the French Revolution, but that was a long time ago. The Revolution started in 1789, so maybe the current capital is a few years after that. I think it's around 2023, so maybe 2024 or 2025. I've heard that Paris is still the most populated city in France, so that makes sense.\\n\\nNow, I should probably check this information to make sure. I think there are some official sources like the French government or reliable geography websites that confirm this. I remember seeing maps of Europe with the capital marked, and Paris is definitely one of them. Also, I've heard Paris is the most visited city in France, so that supports it being the capital.\\n\\nWait, but isn't there a different capital in another country? I think I might have confused it with something else. No, France's capital is definitely Paris. I don't think it's a mistake. Maybe I can think about the political history. The French Revolution started in Paris, so that city was probably the capital until then. But after the revolution, the capital became another city, maybe Toulouse? No, that doesn't sound right. I think after the revolution, Paris remained the capital until it was taken over by the new monarchy.\\n\\nI should also consider the political parties. The current government is the Fifth Republic, led by Jean-Baptiste Pomet. I think that's the current government, so they're probably in charge of the capital. Therefore, I can be confident that Paris is the capital.\\n\\nTo sum it up, I believe the capital of France is Paris. It's the most populated city, the most visited, and it's the capital before the French Revolution. After that, it's still the capital until the new government takes over. So, putting it all together, Paris is the capital of France.\\n</think>\\n\\nThe capital of France is Paris. It is the most populated city, the most visited, and the capital before the French Revolution, which began in 1789. After the revolution, Paris remains the capital until it is taken over by the new French monarchy. As the current government is led by Jean-Baptiste Pomet, Paris continues to be the capital.\",\n",
            "        \"tool_calls\": []\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"stop_reason\": null\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 12,\n",
            "    \"total_tokens\": 631,\n",
            "    \"completion_tokens\": 619,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from fastapi.responses import StreamingResponse\n",
        "import requests\n",
        "\n",
        "# Request schema for input\n",
        "class QuestionRequest(BaseModel):\n",
        "    question: str\n",
        "    # model:model now would be passed from the global model.\n",
        "\n",
        "\n",
        "def ask_model(question: str):\n",
        "    \"\"\"\n",
        "    Sends a request to the model server and fetches a response.\n",
        "    \"\"\"\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"  # Adjust the URL if different\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    response.raise_for_status()  # Raise exception for HTTP errors\n",
        "    return response.json()\n",
        "\n",
        "# Usage:\n",
        "result = ask_model(\"What is the capital of France?\")\n",
        "print(json.dumps(result, indent=2))\n",
        "\n",
        "def stream_llm_response(question:str):\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
        "        \"stream\": True  # 🔥 Enable streaming\n",
        "    }\n",
        "\n",
        "    with requests.post(url, headers=headers, json=data, stream=True) as response:\n",
        "        for line in response.iter_lines():\n",
        "            if line:\n",
        "                # OpenAI-style streaming responses are prefixed with \"data: \"\n",
        "                decoded_line = line.decode(\"utf-8\").replace(\"data: \", \"\")\n",
        "                yield decoded_line + \"\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ0mnu1nl9Ko"
      },
      "source": [
        "## 🌐 第六步：创建 FastAPI Web 服务\n",
        "\n",
        "现在我们将创建一个 FastAPI Web 服务，将 VLLM 模型封装成易于使用的 REST API。\n",
        "\n",
        "### 🎯 FastAPI 服务说明\n",
        "\n",
        "#### 🔧 核心功能\n",
        "1. **RESTful API**: 提供标准的 HTTP 接口\n",
        "2. **自动文档**: 自动生成 Swagger UI 文档\n",
        "3. **数据验证**: 使用 Pydantic 进行请求验证\n",
        "4. **异步支持**: 支持高并发请求处理\n",
        "\n",
        "#### 📡 API 端点设计\n",
        "- **根路径** (`/`): 健康检查端点\n",
        "- **生成回答** (`/api/v1/generate-response`): 获取完整回答\n",
        "- **流式回答** (`/api/v1/generate-response-stream`): 实时流式输出\n",
        "\n",
        "#### 🔒 CORS 配置\n",
        "- 允许跨域访问，支持前端调用\n",
        "- 支持所有 HTTP 方法和头部\n",
        "- 便于与不同前端框架集成\n",
        "\n",
        "### 🚀 服务特点\n",
        "- **高性能**: 基于 ASGI 的异步框架\n",
        "- **易用性**: 简洁的 API 设计\n",
        "- **可扩展**: 支持添加更多功能\n",
        "- **标准化**: 遵循 REST API 设计规范"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2lAE878DSaSk"
      },
      "outputs": [],
      "source": [
        "# 🌐 创建 FastAPI Web 服务\n",
        "# \n",
        "# 这个单元格的作用：\n",
        "# 1. 初始化 FastAPI 应用\n",
        "# 2. 配置 CORS 跨域支持\n",
        "# 3. 定义 API 端点和路由\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "# 🚀 创建 FastAPI 应用实例\n",
        "app = FastAPI(\n",
        "    title=\"DeepSeek R1 API 服务\",\n",
        "    description=\"基于 VLLM 的 DeepSeek R1 蒸馏版模型 API 服务\",\n",
        "    version=\"1.0.0\",\n",
        "    docs_url=\"/docs\",  # Swagger UI 文档地址\n",
        "    redoc_url=\"/redoc\"  # ReDoc 文档地址\n",
        ")\n",
        "\n",
        "# 🔒 配置 CORS 跨域中间件\n",
        "# 允许前端应用从不同域名访问 API\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],        # 允许所有域名（生产环境应限制）\n",
        "    allow_credentials=True,     # 允许携带凭据\n",
        "    allow_methods=['*'],        # 允许所有 HTTP 方法\n",
        "    allow_headers=['*'],        # 允许所有请求头\n",
        ")\n",
        "\n",
        "# 🏠 根路径 - 健康检查端点\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    \"\"\"\n",
        "    🏥 健康检查端点\n",
        "    \n",
        "    返回:\n",
        "        dict: 包含服务状态信息\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'status': 'healthy',\n",
        "        'message': 'DeepSeek R1 API 服务正在运行',\n",
        "        'model': model,\n",
        "        'version': '1.0.0'\n",
        "    }\n",
        "\n",
        "# 🤖 生成完整回答的 API 端点\n",
        "@app.post(\"/api/v1/generate-response\")\n",
        "def generate_response(request: QuestionRequest):\n",
        "    \"\"\"\n",
        "    📝 生成完整回答的 API 端点\n",
        "    \n",
        "    参数:\n",
        "        request (QuestionRequest): 包含用户问题的请求对象\n",
        "    \n",
        "    返回:\n",
        "        dict: 包含模型回答的响应\n",
        "    \n",
        "    异常:\n",
        "        HTTPException: 当模型推理失败时抛出 500 错误\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"📝 收到问题: {request.question}\")\n",
        "        \n",
        "        # 调用模型推理函数\n",
        "        response = ask_model(request.question)\n",
        "        \n",
        "        if response is None:\n",
        "            raise HTTPException(status_code=500, detail=\"模型推理失败\")\n",
        "        \n",
        "        print(\"✅ 推理完成\")\n",
        "        return {\"response\": response}\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 推理过程中出现错误: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=f\"推理失败: {str(e)}\")\n",
        "\n",
        "# 🌊 流式响应的 API 端点\n",
        "@app.post(\"/api/v1/generate-response-stream\")\n",
        "def stream_response(request: QuestionRequest):\n",
        "    \"\"\"\n",
        "    🌊 流式响应 API 端点\n",
        "    \n",
        "    参数:\n",
        "        request (QuestionRequest): 包含用户问题的请求对象\n",
        "    \n",
        "    返回:\n",
        "        StreamingResponse: 实时流式响应\n",
        "    \n",
        "    特点:\n",
        "        - 实时返回生成内容\n",
        "        - 降低用户等待时间\n",
        "        - 提供更好的交互体验\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"🌊 收到流式请求: {request.question}\")\n",
        "        \n",
        "        # 调用流式响应生成器\n",
        "        response_generator = stream_llm_response(request.question)\n",
        "        \n",
        "        return StreamingResponse(\n",
        "            response_generator, \n",
        "            media_type=\"text/event-stream\",\n",
        "            headers={\n",
        "                \"Cache-Control\": \"no-cache\",\n",
        "                \"Connection\": \"keep-alive\",\n",
        "                \"Access-Control-Allow-Origin\": \"*\"\n",
        "            }\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 流式响应过程中出现错误: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=f\"流式响应失败: {str(e)}\")\n",
        "\n",
        "print(\"✅ FastAPI 应用创建完成！\")\n",
        "print(\"📚 API 文档将在启动后访问: http://localhost:8081/docs\")\n",
        "print(\"🔄 准备启动 Web 服务...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYuy3A6HmCma"
      },
      "source": [
        "## 🌐 第六步：Ngrok 注册与配置\n",
        "\n",
        "### 🎯 什么是 Ngrok？\n",
        "\n",
        "Ngrok 是一个强大的内网穿透工具，可以将本地运行的服务暴露到公网上，让外部用户可以访问。在我们的场景中，它可以让其他人通过公网 URL 访问您在 Colab 中部署的模型 API。\n",
        "\n",
        "### 🔧 Ngrok 的作用\n",
        "\n",
        "#### 📡 核心功能\n",
        "1. **内网穿透**: 将本地服务映射到公网域名\n",
        "2. **HTTPS 支持**: 自动提供 HTTPS 加密连接\n",
        "3. **域名分配**: 分配一个临时的公网域名\n",
        "4. **流量监控**: 提供请求日志和监控功能\n",
        "\n",
        "#### 🎯 使用场景\n",
        "- **API 分享**: 与团队成员分享 API 接口\n",
        "- **远程测试**: 在不同设备上测试服务\n",
        "- **演示展示**: 向客户展示项目效果\n",
        "- **Webhook 接收**: 接收第三方服务的回调\n",
        "\n",
        "### 📝 Ngrok 注册流程\n",
        "\n",
        "#### 步骤 1：访问官网注册\n",
        "1. 打开 Ngrok 官网：[https://ngrok.com/](https://ngrok.com/)\n",
        "2. 点击右上角的 **\"Sign up\"** 按钮\n",
        "3. 选择注册方式：\n",
        "   - **GitHub 账号**: 推荐，一键登录\n",
        "   - **Google 账号**: 方便快捷\n",
        "   - **邮箱注册**: 传统方式\n",
        "\n",
        "#### 步骤 2：验证邮箱（如果使用邮箱注册）\n",
        "1. 填写邮箱地址和密码\n",
        "2. 查收验证邮件\n",
        "3. 点击邮件中的验证链接\n",
        "\n",
        "#### 步骤 3：完成账号设置\n",
        "1. 填写基本信息（可选）\n",
        "2. 选择使用目的（个人/商业）\n",
        "3. 完成注册流程\n",
        "\n",
        "### 🔑 获取 Authtoken\n",
        "\n",
        "#### 方法 1：Dashboard 获取\n",
        "1. 登录后进入 [Ngrok Dashboard](https://dashboard.ngrok.com/)\n",
        "2. 在左侧导航栏找到 **\"Your Authtoken\"** 或 **\"Getting Started\"**\n",
        "3. 复制显示的 authtoken（格式类似：`1ABC2def3GHI4jkl5MNO6pqr7STU8vwx9YZ`）\n",
        "\n",
        "#### 方法 2：直接访问链接\n",
        "访问：[https://dashboard.ngrok.com/get-started/your-authtoken](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "\n",
        "### ⚠️ Authtoken 安全提示\n",
        "\n",
        "#### 🔒 安全注意事项\n",
        "1. **保密性**: Token 相当于您的账号密码，不要公开分享\n",
        "2. **定期更换**: 建议定期重置 token 以确保安全\n",
        "3. **权限控制**: 免费账号有使用限制，付费账号功能更多\n",
        "4. **监控使用**: 定期检查 Dashboard 中的使用情况\n",
        "\n",
        "#### 📊 免费账号限制\n",
        "- **并发隧道**: 1个\n",
        "- **连接数**: 40个/分钟\n",
        "- **域名**: 随机分配\n",
        "- **会话时长**: 8小时\n",
        "\n",
        "### 🛠️ Token 配置方法\n",
        "\n",
        "下面的单元格将演示如何配置您的 authtoken："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG8QGlyjU61y",
        "outputId": "687028d9-a1d0-476b-d514-2424e4345b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# 🔑 配置 Ngrok Authtoken\n",
        "# \n",
        "# ⚠️ 重要提示：请将下面的 YOUR_AUTHTOKEN_HERE 替换为您从 Ngrok Dashboard 获取的真实 token\n",
        "# \n",
        "# 🔗 获取 token 的步骤：\n",
        "# 1. 访问：https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# 2. 登录您的 Ngrok 账号\n",
        "# 3. 复制显示的 authtoken\n",
        "# 4. 替换下面代码中的 YOUR_AUTHTOKEN_HERE\n",
        "\n",
        "# 📝 示例 token 格式（请替换为您的真实 token）：\n",
        "# YOUR_AUTHTOKEN = \"1ABC2def3GHI4jkl5MNO6pqr7STU8vwx9YZ\"\n",
        "\n",
        "# 🚨 请在下面填入您的真实 authtoken\n",
        "YOUR_AUTHTOKEN = \"YOUR_AUTHTOKEN_HERE\"  # 👈 请替换这里\n",
        "\n",
        "# 验证 token 是否已设置\n",
        "if YOUR_AUTHTOKEN == \"YOUR_AUTHTOKEN_HERE\":\n",
        "    print(\"❌ 请先设置您的 Ngrok authtoken！\")\n",
        "    print(\"📝 步骤：\")\n",
        "    print(\"1. 访问 https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "    print(\"2. 登录并复制您的 authtoken\")\n",
        "    print(\"3. 将上面的 YOUR_AUTHTOKEN_HERE 替换为您的真实 token\")\n",
        "    print(\"4. 重新运行此单元格\")\n",
        "else:\n",
        "    # 配置 authtoken\n",
        "    import subprocess\n",
        "    result = subprocess.run(['ngrok', 'config', 'add-authtoken', YOUR_AUTHTOKEN], \n",
        "                          capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(\"✅ Ngrok authtoken 配置成功！\")\n",
        "        print(\"🎉 现在可以创建公网隧道了\")\n",
        "    else:\n",
        "        print(f\"❌ 配置失败: {result.stderr}\")\n",
        "        print(\"💡 请检查 token 是否正确\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🚀 第七步：启动 Ngrok 隧道\n",
        "\n",
        "### 🌐 创建公网隧道\n",
        "\n",
        "配置好 authtoken 后，我们就可以创建 ngrok 隧道，将本地的 FastAPI 服务暴露到公网。\n",
        "\n",
        "### 🔧 Ngrok 隧道工作原理\n",
        "\n",
        "#### 📡 隧道机制\n",
        "1. **本地服务**: FastAPI 在 localhost:8081 运行\n",
        "2. **Ngrok 客户端**: 连接到 Ngrok 服务器\n",
        "3. **公网域名**: Ngrok 分配一个临时域名\n",
        "4. **流量转发**: 外部请求通过域名转发到本地服务\n",
        "\n",
        "#### 🌍 访问流程\n",
        "```\n",
        "外部用户 → https://abc123.ngrok.io → Ngrok服务器 → 本地FastAPI服务\n",
        "```\n",
        "\n",
        "### 📊 Ngrok 功能特性\n",
        "\n",
        "#### ✨ 主要功能\n",
        "- **HTTPS 加密**: 自动提供 SSL 证书\n",
        "- **实时监控**: Web 界面查看请求日志\n",
        "- **多种协议**: 支持 HTTP、HTTPS、TCP 等\n",
        "- **自定义域名**: 付费版支持自定义域名\n",
        "\n",
        "#### 🎯 适用场景\n",
        "- **API 测试**: 让前端开发者测试 API\n",
        "- **移动端调试**: 手机直接访问本地服务\n",
        "- **第三方集成**: 接收 Webhook 回调\n",
        "- **临时演示**: 快速分享项目成果\n",
        "\n",
        "### ⚠️ 注意事项\n",
        "\n",
        "#### 🔒 安全提醒\n",
        "1. **临时使用**: 隧道域名是临时的，重启后会变化\n",
        "2. **流量限制**: 免费版有并发和流量限制\n",
        "3. **安全风险**: 公网可访问，注意数据安全\n",
        "4. **监控访问**: 定期检查访问日志\n",
        "\n",
        "#### 📈 性能考虑\n",
        "- **延迟增加**: 通过 Ngrok 会增加网络延迟\n",
        "- **带宽限制**: 免费版有带宽限制\n",
        "- **稳定性**: 网络不稳定可能导致连接中断\n",
        "\n",
        "下面的单元格将创建 Ngrok 隧道：\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHI9RCHdmJDf"
      },
      "source": [
        "### 🌐 创建 Ngrok 隧道和启动服务\n",
        "\n",
        "现在我们将同时：\n",
        "1. 创建 Ngrok 隧道，将本地服务暴露到公网\n",
        "2. 启动 FastAPI 服务，提供 API 接口\n",
        "\n",
        "#### 🔄 执行顺序\n",
        "- 先创建 Ngrok 隧道（获取公网 URL）\n",
        "- 然后启动 FastAPI 服务（在指定端口运行）\n",
        "- 外部用户可以通过公网 URL 访问 API\n",
        "\n",
        "#### 💡 使用提示\n",
        "- 隧道创建成功后会显示公网 URL\n",
        "- 请保存这个 URL，用于外部访问\n",
        "- 服务启动后会阻塞当前单元格，这是正常现象\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyiHoZEwG4gH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "QQ3NYyCgTUdj",
        "outputId": "56614231-b51f-4eae-eb02-a699ea62b225"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-07-13T04:45:27+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: The authtoken you specified is properly formed, but it is invalid.\\nYour authtoken: 1tLoo3XnYGauKTuogau9wULVVif_7S2sJK2CCLRLuwYNAwbcJ\\nThis usually happens when:\\n    - You reset your authtoken\\n    - Your authtoken was for a team account that you were removed from\\n    - You are using ngrok link and this credential was explicitly revoked\\nGo to your ngrok dashboard and double check that your authtoken is correct:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_107\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-13T04:45:27+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: The authtoken you specified is properly formed, but it is invalid.\\nYour authtoken: 1tLoo3XnYGauKTuogau9wULVVif_7S2sJK2CCLRLuwYNAwbcJ\\nThis usually happens when:\\n    - You reset your authtoken\\n    - Your authtoken was for a team account that you were removed from\\n    - You are using ngrok link and this credential was explicitly revoked\\nGo to your ngrok dashboard and double check that your authtoken is correct:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_107\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-13T04:45:27+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: The authtoken you specified is properly formed, but it is invalid.\\nYour authtoken: 1tLoo3XnYGauKTuogau9wULVVif_7S2sJK2CCLRLuwYNAwbcJ\\nThis usually happens when:\\n    - You reset your authtoken\\n    - Your authtoken was for a team account that you were removed from\\n    - You are using ngrok link and this credential was explicitly revoked\\nGo to your ngrok dashboard and double check that your authtoken is correct:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_107\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-07-13T04:45:27+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: The authtoken you specified is properly formed, but it is invalid.\\nYour authtoken: 1tLoo3XnYGauKTuogau9wULVVif_7S2sJK2CCLRLuwYNAwbcJ\\nThis usually happens when:\\n    - You reset your authtoken\\n    - Your authtoken was for a team account that you were removed from\\n    - You are using ngrok link and this credential was explicitly revoked\\nGo to your ngrok dashboard and double check that your authtoken is correct:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_107\\r\\n\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-07-13T04:45:27+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context canceled\"\n"
          ]
        },
        {
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: The authtoken you specified is properly formed, but it is invalid.\\nYour authtoken: 1tLoo3XnYGauKTuogau9wULVVif_7S2sJK2CCLRLuwYNAwbcJ\\nThis usually happens when:\\n    - You reset your authtoken\\n    - Your authtoken was for a team account that you were removed from\\n    - You are using ngrok link and this credential was explicitly revoked\\nGo to your ngrok dashboard and double check that your authtoken is correct:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_107\\r\\n.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-3283467392.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8081\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 打开到 HTTP 服务器的 ngrok 隧道\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" * ngrok 隧道 \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: The authtoken you specified is properly formed, but it is invalid.\\nYour authtoken: 1tLoo3XnYGauKTuogau9wULVVif_7S2sJK2CCLRLuwYNAwbcJ\\nThis usually happens when:\\n    - You reset your authtoken\\n    - Your authtoken was for a team account that you were removed from\\n    - You are using ngrok link and this credential was explicitly revoked\\nGo to your ngrok dashboard and double check that your authtoken is correct:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_107\\r\\n."
          ]
        }
      ],
      "source": [
        "# 🌐 创建 Ngrok 隧道\n",
        "# \n",
        "# 这个单元格的作用：\n",
        "# 1. 设置 FastAPI 服务的端口\n",
        "# 2. 创建 Ngrok 隧道连接到该端口\n",
        "# 3. 获取公网访问 URL\n",
        "\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 📡 设置服务端口\n",
        "port = 8081\n",
        "print(f\"🚀 准备在端口 {port} 上启动服务...\")\n",
        "\n",
        "try:\n",
        "    # 🌐 创建 Ngrok 隧道\n",
        "    print(\"🔗 正在创建 Ngrok 隧道...\")\n",
        "    \n",
        "    # 创建 HTTP 隧道\n",
        "    public_url = ngrok.connect(port).public_url\n",
        "    \n",
        "    print(\"✅ Ngrok 隧道创建成功！\")\n",
        "    print(f\"🌍 公网访问地址: {public_url}\")\n",
        "    print(f\"🔗 本地地址: http://127.0.0.1:{port}\")\n",
        "    print()\n",
        "    print(\"📚 API 文档地址:\")\n",
        "    print(f\"   • Swagger UI: {public_url}/docs\")\n",
        "    print(f\"   • ReDoc: {public_url}/redoc\")\n",
        "    print()\n",
        "    print(\"🧪 API 端点:\")\n",
        "    print(f\"   • 健康检查: {public_url}/\")\n",
        "    print(f\"   • 生成回答: {public_url}/api/v1/generate-response\")\n",
        "    print(f\"   • 流式回答: {public_url}/api/v1/generate-response-stream\")\n",
        "    print()\n",
        "    print(\"💡 提示：请保存上面的公网地址，用于外部访问\")\n",
        "    \n",
        "    # 🔍 显示 Ngrok 监控信息\n",
        "    tunnels = ngrok.get_tunnels()\n",
        "    if tunnels:\n",
        "        print(\"\\n📊 当前活跃隧道:\")\n",
        "        for tunnel in tunnels:\n",
        "            print(f\"   • {tunnel.name}: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ 创建 Ngrok 隧道失败: {e}\")\n",
        "    print(\"🔧 可能的解决方案:\")\n",
        "    print(\"1. 检查 authtoken 是否正确配置\")\n",
        "    print(\"2. 确认网络连接正常\")\n",
        "    print(\"3. 检查是否超出免费版限制\")\n",
        "    print(\"4. 重新运行 authtoken 配置单元格\")\n",
        "    \n",
        "    # 显示当前配置的 authtoken（部分遮蔽）\n",
        "    try:\n",
        "        import subprocess\n",
        "        result = subprocess.run(['ngrok', 'config', 'check'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"\\n📋 当前 Ngrok 配置状态: 正常\")\n",
        "        else:\n",
        "            print(f\"\\n❌ Ngrok 配置检查失败: {result.stderr}\")\n",
        "    except:\n",
        "        print(\"\\n⚠️ 无法检查 Ngrok 配置状态\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_3xOk2mY55g"
      },
      "outputs": [],
      "source": [
        "# 🚀 启动 FastAPI Web 服务\n",
        "# \n",
        "# 这个单元格的作用：\n",
        "# 1. 应用 nest_asyncio 解决 Jupyter 环境的异步问题\n",
        "# 2. 使用 uvicorn 启动 FastAPI 应用\n",
        "# 3. 在指定端口上运行 Web 服务，通过 Ngrok 隧道对外提供服务\n",
        "\n",
        "print(\"🚀 启动 FastAPI Web 服务...\")\n",
        "print(f\"📡 本地服务端口: {port}\")\n",
        "if 'public_url' in globals():\n",
        "    print(f\"🌍 公网访问地址: {public_url}\")\n",
        "    print(f\"📚 API 文档: {public_url}/docs\")\n",
        "else:\n",
        "    print(\"⚠️ 未检测到 Ngrok 隧道，请先运行上一个单元格\")\n",
        "\n",
        "print()\n",
        "print(\"🎯 服务功能:\")\n",
        "print(\"   • 健康检查 API\")\n",
        "print(\"   • 模型问答 API（同步）\")\n",
        "print(\"   • 模型问答 API（流式）\")\n",
        "print(\"   • 自动生成的 API 文档\")\n",
        "print()\n",
        "print(\"💡 提示：\")\n",
        "print(\"   • 服务启动后会阻塞当前单元格（这是正常现象）\")\n",
        "print(\"   • 可以在新标签页中访问 API 文档进行测试\")\n",
        "print(\"   • 按 Ctrl+C 或中断内核可以停止服务\")\n",
        "print(\"   • 停止服务后 Ngrok 隧道也会关闭\")\n",
        "\n",
        "# 应用 nest_asyncio 以在 Jupyter 环境中运行异步代码\n",
        "nest_asyncio.apply()\n",
        "\n",
        "try:\n",
        "    # 启动 FastAPI 应用\n",
        "    # host=\"0.0.0.0\" 允许外部访问（通过 Ngrok 隧道）\n",
        "    # port=port 使用之前定义的端口\n",
        "    print(f\"\\n🔄 正在启动服务...\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n🛑 服务已停止\")\n",
        "    print(\"💡 如需重新启动，请重新运行此单元格\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ 服务启动失败: {e}\")\n",
        "    print(\"🔧 可能的解决方案:\")\n",
        "    print(\"1. 检查端口是否被占用\")\n",
        "    print(\"2. 确认 VLLM 服务正在运行\")\n",
        "    print(\"3. 重新运行依赖安装单元格\")\n",
        "finally:\n",
        "    # 清理 Ngrok 隧道\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "        print(\"🧹 Ngrok 隧道已清理\")\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YRmAQ7Emovh"
      },
      "source": [
        "## 🧪 第八步：API 使用示例\n",
        "\n",
        "服务启动成功后，您可以通过多种方式调用 API。\n",
        "\n",
        "### 📡 API 调用方式\n",
        "\n",
        "#### 1. 🌐 浏览器访问\n",
        "- **本地访问**: \n",
        "  - API 文档: `http://localhost:8081/docs` (Swagger UI)\n",
        "  - 健康检查: `http://localhost:8081/`\n",
        "- **公网访问**（通过 Ngrok）:\n",
        "  - API 文档: `https://您的ngrok地址/docs`\n",
        "  - 健康检查: `https://您的ngrok地址/`\n",
        "\n",
        "#### 2. 📱 命令行调用 (cURL)\n",
        "使用 cURL 命令行工具测试 API 接口\n",
        "\n",
        "#### 3. 🐍 Python 调用\n",
        "使用 requests 库或其他 HTTP 客户端\n",
        "\n",
        "#### 4. 🌍 移动端/远程访问\n",
        "通过 Ngrok 提供的公网 URL，可以在任何设备上访问\n",
        "\n",
        "### 🔧 请求格式说明\n",
        "- **Content-Type**: `application/json`\n",
        "- **请求体**: JSON 格式，包含 `question` 字段\n",
        "- **响应**: JSON 格式，包含模型回答\n",
        "\n",
        "### 🌐 Ngrok 公网访问优势\n",
        "\n",
        "#### ✨ 主要优势\n",
        "1. **跨设备访问**: 手机、平板、其他电脑都可以访问\n",
        "2. **团队协作**: 团队成员可以直接测试您的 API\n",
        "3. **真实环境**: 模拟真实的网络环境和延迟\n",
        "4. **HTTPS 支持**: 自动提供 SSL 加密，安全可靠\n",
        "\n",
        "#### 📱 使用场景\n",
        "- **移动端测试**: 在手机上直接测试 API\n",
        "- **远程演示**: 向客户或同事展示项目\n",
        "- **前端集成**: 前端开发者可以直接调用 API\n",
        "- **第三方集成**: 支持 Webhook 等第三方服务\n",
        "\n",
        "### 💡 使用提示\n",
        "- 优先使用 Ngrok 提供的 HTTPS 地址\n",
        "- 本地测试可以使用 localhost 地址\n",
        "- 注意请求和响应的 JSON 格式\n",
        "- 可以通过 Swagger UI 进行交互式测试\n",
        "- Ngrok 地址每次重启都会变化，注意更新"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE5HRXATmrWa"
      },
      "outputs": [],
      "source": [
        "### 📱 cURL 命令示例\n",
        "\n",
        "#### 🌐 本地访问 - 生成完整回答\n",
        "```bash\n",
        "curl --location 'http://localhost:8081/api/v1/generate-response' \\\n",
        "--header 'Content-Type: application/json' \\\n",
        "--data '{\n",
        "    \"question\": \"巴黎在哪里？\"\n",
        "}'\n",
        "```\n",
        "\n",
        "#### 🌍 公网访问示例（需要替换为实际的 ngrok 地址）\n",
        "```bash\n",
        "curl --location 'https://你的ngrok地址/api/v1/generate-response' \\\n",
        "--header 'Content-Type: application/json' \\\n",
        "--data '{\n",
        "    \"question\": \"巴黎在哪里？\"\n",
        "}'\n",
        "```\n",
        "\n",
        "#### 🌊 流式响应示例\n",
        "```bash\n",
        "curl --location 'http://localhost:8081/api/v1/generate-response-stream' \\\n",
        "--header 'Content-Type: application/json' \\\n",
        "--data '{\n",
        "    \"question\": \"请详细介绍一下人工智能的发展历史\"\n",
        "}'\n",
        "```\n",
        "\n",
        "#### 🔧 参数说明\n",
        "- `--location`: 跟随 HTTP 重定向\n",
        "- `--header`: 设置请求头，指定内容类型\n",
        "- `--data`: 发送 JSON 格式的请求体"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYXWde1knE2T"
      },
      "source": [
        "## 📋 API 响应示例\n",
        "\n",
        "### 🤖 完整响应格式\n",
        "\n",
        "当您调用 `/api/v1/generate-response` 端点时，会收到如下格式的 JSON 响应：\n",
        "\n",
        "#### 📊 响应结构说明\n",
        "- **id**: 请求的唯一标识符\n",
        "- **object**: 响应对象类型\n",
        "- **created**: 响应创建时间戳\n",
        "- **model**: 使用的模型名称\n",
        "- **choices**: 模型生成的选择列表\n",
        "  - **index**: 选择的索引\n",
        "  - **message**: 消息内容\n",
        "    - **role**: 角色（assistant）\n",
        "    - **content**: 模型生成的回答\n",
        "  - **finish_reason**: 完成原因（stop 表示正常结束）\n",
        "- **usage**: 令牌使用统计\n",
        "  - **prompt_tokens**: 输入令牌数\n",
        "  - **completion_tokens**: 生成令牌数\n",
        "  - **total_tokens**: 总令牌数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXziLO52nH1e"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"id\": \"chatcmpl-680bc07cd6de42e7a00a50dfbd99e833\",\n",
        "  \"object\": \"chat.completion\",\n",
        "  \"created\": 1738129381,\n",
        "  \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "  \"choices\": [\n",
        "    {\n",
        "      \"index\": 0,\n",
        "      \"message\": {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"<think>\\nOkay, so I'm trying to find out what the capital of France is. Hmm, I remember hearing a few cities named after the myths or something. Let me think. I think Neuch portfolio is where the comma was named. Yeah, that's right, until sometimes they changed it, but I think it's still there now. Then there's Charles-de-Lorraine. I've seen that name written before in various contexts, maybe managers or something. And then I think there's Saint Mal\\u25e6e as a significant city in France. Wait, I'm a bit confused about the last one. Is that the capital or somewhere else? I think the capital blew my mind once, and I still don't recall it. Let me think of the names that come to mind. Maybe Paris? But is there something else? I've heard about places likequalification, Guiness, and Agoura also named after mythological figures, but are they capitals? I don't think so. So among the prominent ones, maybe Neuch portfolio, Charles-de-Lorraine, and Saint Mal\\u25e6e are the names intended for the capital, but I'm unsure which one it is. Wait, I think I might have confused some of them. Let me try to look up the actual capital. The capital of France is a city in the eastern department of\\u5c55\\u51fa. Oh, right, there's a special place called Place de la Confluense. Maybe that's where the capital is. So I think the capital is Place de la Confluense, not the city name. So the capital isn't the town; it's quite a vein-shaped area. But I'm a bit confused because some people might refer to just the town as the capital, but in reality, it's a larger area. So to answer the question, the capital of France is Place de la Confluense, and its formal name is la Confluense. I'm not entirely certain if there are any other significant cities or names, but from what I know, the others I listed might be historical places but not exactly capitals. Maybe the\\u6bebot\\u00e9 family name is still sometimes used for the capital, but I think it's not the actual name. So putting it all together, the capital is Place de la Confluense, and the correct name is \\\"la Confluense.\\\" The other names like Neuch portfolio are places, not capitals. So, overall, my answer would be the capital is la Confluense named at Place de la Confluense.\\n</think>\\n\\nThe capital of France is called Place de la Confluense. Its official name is \\\"la Confluense.\\\"\",\n",
        "        \"tool_calls\": []\n",
        "      },\n",
        "      \"logprobs\": null,\n",
        "      \"finish_reason\": \"stop\",\n",
        "      \"stop_reason\": null\n",
        "    }\n",
        "  ],\n",
        "  \"usage\": {\n",
        "    \"prompt_tokens\": 10,\n",
        "    \"total_tokens\": 550,\n",
        "    \"completion_tokens\": 540,\n",
        "    \"prompt_tokens_details\": null\n",
        "  },\n",
        "  \"prompt_logprobs\": null\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRer8bosm041"
      },
      "source": [
        "### 🌊 流式响应格式\n",
        "\n",
        "当您调用 `/api/v1/generate-response-stream` 端点时，会收到一系列 JSON 对象，每个对象代表生成过程中的一个步骤：\n",
        "\n",
        "#### 📡 流式响应特点\n",
        "- **实时性**: 逐步返回生成内容，无需等待完整回答\n",
        "- **低延迟**: 用户可以立即看到模型开始生成\n",
        "- **更好体验**: 适合长文本生成和实时对话\n",
        "\n",
        "#### 🔄 流式数据格式\n",
        "每行数据都是一个独立的 JSON 对象，包含：\n",
        "- **id**: 请求标识符（整个流中保持一致）\n",
        "- **object**: \"chat.completion.chunk\"\n",
        "- **created**: 时间戳\n",
        "- **model**: 模型名称\n",
        "- **choices**: 当前生成的内容块\n",
        "  - **index**: 选择索引\n",
        "  - **delta**: 增量内容\n",
        "    - **content**: 新生成的文本片段\n",
        "  - **finish_reason**: 结束原因（null 表示继续，\"stop\" 表示结束）\n",
        "\n",
        "#### 💡 使用建议\n",
        "- 适合需要实时反馈的应用场景\n",
        "- 可以实现打字机效果的用户界面\n",
        "- 对于长文本生成特别有用"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Ngrok 管理和监控\n",
        "\n",
        "### 🔍 监控隧道状态\n",
        "\n",
        "Ngrok 提供了丰富的监控和管理功能，帮助您了解 API 的使用情况。\n",
        "\n",
        "#### 🌐 Web 监控界面\n",
        "当 Ngrok 隧道运行时，您可以访问本地监控界面：\n",
        "- **监控地址**: `http://localhost:4040`\n",
        "- **功能**: 实时查看请求日志、响应时间、错误统计等\n",
        "\n",
        "#### 📊 监控功能\n",
        "1. **请求日志**: 查看所有通过隧道的 HTTP 请求\n",
        "2. **响应详情**: 查看请求和响应的完整内容\n",
        "3. **性能指标**: 响应时间、状态码分布等\n",
        "4. **重放功能**: 重新发送之前的请求进行测试\n",
        "\n",
        "### 🛠️ 隧道管理\n",
        "\n",
        "#### 📋 查看活跃隧道\n",
        "```python\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 获取所有活跃隧道\n",
        "tunnels = ngrok.get_tunnels()\n",
        "for tunnel in tunnels:\n",
        "    print(f\"隧道名称: {tunnel.name}\")\n",
        "    print(f\"公网地址: {tunnel.public_url}\")\n",
        "    print(f\"本地地址: {tunnel.config['addr']}\")\n",
        "    print(\"---\")\n",
        "```\n",
        "\n",
        "#### 🔄 重启隧道\n",
        "```python\n",
        "# 关闭特定隧道\n",
        "ngrok.disconnect(public_url)\n",
        "\n",
        "# 关闭所有隧道\n",
        "ngrok.kill()\n",
        "\n",
        "# 重新创建隧道\n",
        "new_tunnel = ngrok.connect(8081)\n",
        "```\n",
        "\n",
        "### 🔧 高级配置\n",
        "\n",
        "#### 🎯 自定义隧道配置\n",
        "```python\n",
        "# 创建带自定义配置的隧道\n",
        "tunnel = ngrok.connect(\n",
        "    port=8081,\n",
        "    options={\n",
        "        \"bind_tls\": True,  # 只使用 HTTPS\n",
        "        \"subdomain\": \"my-api\",  # 自定义子域名（需要付费版）\n",
        "        \"basic_auth\": \"user:pass\"  # 基础认证（需要付费版）\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "#### 📈 性能优化\n",
        "1. **区域选择**: 选择距离用户最近的 Ngrok 服务器\n",
        "2. **连接复用**: 避免频繁创建和销毁隧道\n",
        "3. **压缩传输**: 启用 gzip 压缩减少带宽使用\n",
        "\n",
        "### ⚠️ 最佳实践\n",
        "\n",
        "#### 🔒 安全建议\n",
        "1. **定期更换 Token**: 定期重置 authtoken\n",
        "2. **监控访问**: 定期检查访问日志，发现异常访问\n",
        "3. **限制访问**: 考虑添加基础认证或 IP 白名单\n",
        "4. **及时关闭**: 不使用时及时关闭隧道\n",
        "\n",
        "#### 📊 性能监控\n",
        "- 定期检查响应时间和错误率\n",
        "- 监控带宽使用情况\n",
        "- 关注并发连接数\n",
        "\n",
        "### 🆘 故障排除\n",
        "\n",
        "#### 常见问题及解决方案\n",
        "\n",
        "1. **隧道连接失败**\n",
        "   - 检查网络连接\n",
        "   - 验证 authtoken 是否正确\n",
        "   - 确认是否超出免费版限制\n",
        "\n",
        "2. **访问速度慢**\n",
        "   - 选择更近的服务器区域\n",
        "   - 检查本地网络状况\n",
        "   - 考虑升级到付费版\n",
        "\n",
        "3. **隧道意外断开**\n",
        "   - 检查网络稳定性\n",
        "   - 设置自动重连机制\n",
        "   - 监控隧道状态\n",
        "\n",
        "通过合理使用 Ngrok 的这些功能，您可以更好地管理和监控您的 API 服务！\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎉 实验完成总结\n",
        "\n",
        "恭喜您完成了 DeepSeek R1 蒸馏版 Qwen 1.5B 模型的完整部署实验！\n",
        "\n",
        "### 📚 您已经学会了：\n",
        "\n",
        "#### 🔧 技术技能\n",
        "1. **环境检查**: 如何检查和确认 Google Colab 的硬件环境\n",
        "2. **依赖管理**: 安装和配置 VLLM、FastAPI 等关键库\n",
        "3. **模型部署**: 使用 VLLM 部署大语言模型的完整流程\n",
        "4. **API 开发**: 创建 RESTful API 服务的方法\n",
        "5. **服务监控**: 监控和调试模型服务的技巧\n",
        "\n",
        "#### 🚀 实践经验\n",
        "- **免费资源利用**: 充分利用 Google Colab 的免费 GPU 资源\n",
        "- **异步编程**: 理解异步服务和流式响应的实现\n",
        "- **错误处理**: 学会处理模型部署中的常见问题\n",
        "- **API 设计**: 掌握现代 Web API 的设计原则\n",
        "\n",
        "### 🎯 项目成果\n",
        "\n",
        "您现在拥有了：\n",
        "- ✅ 一个完整的大语言模型 API 服务\n",
        "- ✅ 支持同步和流式两种响应模式\n",
        "- ✅ 完整的 API 文档和测试方法\n",
        "- ✅ 可扩展的代码架构\n",
        "\n",
        "### 🔄 后续扩展建议\n",
        "\n",
        "#### 🌟 功能增强\n",
        "1. **多轮对话**: 添加会话管理和上下文记忆\n",
        "2. **参数调优**: 支持温度、top_p 等参数的动态调整\n",
        "3. **模型切换**: 支持多个模型的动态切换\n",
        "4. **批量处理**: 实现批量请求处理功能\n",
        "\n",
        "#### 🛡️ 生产优化\n",
        "1. **安全认证**: 添加 API 密钥或 JWT 认证\n",
        "2. **限流控制**: 实现请求频率限制\n",
        "3. **监控告警**: 添加性能监控和告警系统\n",
        "4. **负载均衡**: 支持多实例部署和负载均衡\n",
        "\n",
        "#### 🎨 用户体验\n",
        "1. **前端界面**: 开发 Web 前端界面\n",
        "2. **移动应用**: 创建移动端应用\n",
        "3. **插件开发**: 开发浏览器插件或编辑器插件\n",
        "\n",
        "### 📖 学习资源\n",
        "\n",
        "继续深入学习的推荐资源：\n",
        "- [VLLM 官方文档](https://vllm.readthedocs.io/)\n",
        "- [FastAPI 官方文档](https://fastapi.tiangolo.com/)\n",
        "- [DeepSeek 模型系列](https://huggingface.co/deepseek-ai)\n",
        "- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)\n",
        "\n",
        "### 🤝 分享与交流\n",
        "\n",
        "如果这个实验对您有帮助，欢迎：\n",
        "- ⭐ 给项目点个星\n",
        "- 🔄 分享给更多朋友\n",
        "- 💬 提出问题和建议\n",
        "- 🚀 基于此项目继续创新\n",
        "\n",
        "感谢您的学习和实践！🎊\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l51K5q5Cmwu_"
      },
      "outputs": [],
      "source": [
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"<think>\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"</think>\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" capital\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" city\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" France\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" fullest\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" commercial\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" cultural\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" center\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Region\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" which\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" larger\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" administrative\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" division\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" in\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" France\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" located\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" in\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" northern\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" France\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" near\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Mediterranean\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Sea\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Here\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"'s\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" brief\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" overview\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\":\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" **\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Ge\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ographical\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Location\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"**:\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" approximately\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"4\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" degrees\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" latitude\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" north\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" equ\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ator\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"2\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" degrees\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" longitude\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" east\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" prime\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" mer\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"idian\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" It\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" lies\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" on\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" edge\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Atlantic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Ocean\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" equ\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"id\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"istant\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" from\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" East\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" intriguing\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Atlantic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Ocean\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" co\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"asts\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Atlantic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Forest\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" in\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Atlantic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"挽救\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ais\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" co\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"asts\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" **\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"City\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Size\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"**:\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" fourth\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-largest\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" city\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" in\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" France\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" by\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" population\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" with\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" approximately\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"2\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"2\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" million\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" residents\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" It\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" significant\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" economic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" hub\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" cultural\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" center\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" with\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" an\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" international\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" cuisine\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" artistic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" scene\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" vibrant\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" shopping\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" industry\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" **\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Tour\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ist\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" At\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"traction\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"**:\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" renowned\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" as\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" an\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" International\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".unwrap\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" appealing\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" destination\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" for\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" tourists\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" particularly\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Rome\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ans\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" It\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" hosts\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" major\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" attractions\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" such\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" as\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\":\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" -\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" **\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" PY\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"MO\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"U\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"艺术\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"博物馆\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"**:\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" A\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" world\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-ren\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"owned\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" museum\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" dedicated\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" to\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" work\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ad\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ore\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"PY\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"MO\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"U\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" founding\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" father\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" modern\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" post\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Modern\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ism\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" -\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" **\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"//--\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Des\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" V\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"icts\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"annot\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"汽车\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"城\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"**:\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" A\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" historical\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" automobile\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" museum\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" bit\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" rethink\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"er\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" hub\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" -\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" **\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Font\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"灾区\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"]).\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" -\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Ph\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ine\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"um\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\":\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" A\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" science\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" culture\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" museum\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" that\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" includes\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" ‘\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Sound\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ings\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"しかも\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"s\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"’\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" -\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"\\n    \\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" also\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" major\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" economic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" financial\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" hub\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" hosting\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" over\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"1\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"0\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"0\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"0\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" major\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" destinations\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" attractions\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" from\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" around\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" world\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" gateway\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" to\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" across\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" France\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" its\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" surrounding\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" regions\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" offering\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" mix\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" historic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" acad\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"em\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ical\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" areas\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" modern\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Diane\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Mar\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" [];\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" French\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-speaking\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" communities\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" are\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" largest\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" in\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Europe\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" with\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" twenty\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-six\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" languages\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" spoken\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" known\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" as\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" center\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" finance\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" business\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" finance\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" with\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" investor\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ren\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"It\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"'s\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" one\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" the\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" oldest\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" cities\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" in\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Europe\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" once\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"eda\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" long\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"elled\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" with\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" its\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Roman\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" town\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" center\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" Paris\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" is\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" known\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" for\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" its\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" classification\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" as\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" an\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" old\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" important\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" necessary\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" center\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" of\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" culture\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" economy\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\",\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" history\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\\n\\n\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"It\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"'s\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" well\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"-\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"reserved\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" has\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" a\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" rich\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" artistic\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" and\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" cultural\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" heritage\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\".\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-517e76791b064702b90113cccbc8d61e\",\"object\":\"chat.completion.chunk\",\"created\":1738128620,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}]}\n",
        "[DONE]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbY6mDWCmTsf"
      },
      "source": [
        "### Kill the VLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQbgsTX83j8i"
      },
      "outputs": [],
      "source": [
        "vllm_process.terminate()\n",
        "vllm_process.wait()  # Wait for process to terminate"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
